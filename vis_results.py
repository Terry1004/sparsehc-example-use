# -*- coding: utf-8 -*-

from matplotlib import pyplot as plt
import argparse
import codecs
from con_sql import spend_time_wrapper, connect_to_db, create_cursor, get_k_sentences

# miscellaneous
def to_string(cluster):
    cluster_str = ', '.join(cluster) + '\n'
    return cluster_str

# record cluster results
def print_cl_progress(l_history, sentences, rec_sen = True):
    len_sen = len(sentences)
    assert len(l_history) == len_sen - 1
    
    with open('results.txt', 'w') as results_file:
        for i, entry in enumerate(l_history):
            results_file.write('%d %d %d %.5f\n' %(i, entry[0], entry[1], entry[2]))
    if rec_sen:
        with codecs.open('sentences.txt', 'w', encoding = 'utf-8') as sentences_file:
            for sentence in sentences:
                sentences_file.write('%s\n' %(sentence))

# record the clustering results at a certain step in txt file while also printing on screen
def print_clusters(clusters, step):
    print('step: %s' % step)
    with codecs.open('clusters.txt', 'w', encoding = 'utf-8') as f:
        for key, cluster in clusters.iteritems():
            cluster_str = to_string(cluster)
            print(cluster_str)
            f.write('%s\n' % cluster_str)

# read from sentences file (or database) and results file to obtain the clustering results at a certain step
def parse_sen(sentences_file):
    sentences = []
    with codecs.open(sentences_file, 'r', encoding = 'utf-8') as f:
        for line in f:
            sentences.append(line[: -1])
    return sentences

def parse_results_line(line, len_sen, clusters):
    entry_list = line.split(' ')
    step = int(entry_list[0])
    cluster_1_key = int(entry_list[1])
    cluster_2_key = int(entry_list[2])
    cluster_merge = clusters[cluster_1_key] + clusters[cluster_2_key]
    clusters.pop(cluster_1_key)
    clusters.pop(cluster_2_key)
    clusters[len_sen + step] = cluster_merge

def get_sentences_db(host, port, user, passwd, db, len_sen, get_sen_sql):
    db = connect_to_db(host, port, user, passwd, db)
    cursor = create_cursor(db)
    sentences = get_k_sentences(cursor, len_sen, get_sen_sql)
    return sentences

def init_clusters(sentences):
    clusters = {}
    for i in range(len(sentences)):
        clusters[i] = (sentences[i],)
    return clusters

def update_clusters(results_file, len_sen, clusters, step):
    counter = 0    
    with open(results_file, 'r') as f:
        for line in f:
            if counter > step:
                break
            else:
                parse_results_line(line, len_sen, clusters)
                counter += 1
    return clusters

def print_cl_from_txt(results_file, step, from_db = False, 
                      host = None, port = None, user = None, passwd = None, db = None, 
                      len_sen = None, get_sen_sql = None, sentences_file = None):
    print_clusters(cl_from_txt(results_file, step, from_db = from_db, 
                               host = host, port = port, user = user, passwd = passwd, db = db, 
                               len_sen = len_sen, get_sen_sql = get_sen_sql, sentences_file = sentences_file), step)

def cl_from_txt(results_file, step, from_db = False, 
                host = None, port = None, user = None, passwd = None, db = None,
                len_sen = None, get_sen_sql = None, sentences_file = None):
    
    if from_db:
        sentences = get_sentences_db(host, port, user, passwd, db, len_sen, get_sen_sql)
    else:
        sentences = parse_sen(sentences_file)
    clusters = init_clusters(sentences)
    clusters = update_clusters(results_file, len(sentences), clusters, step)
    return clusters

# plot the graph of distance vs steps from the recorded results file
def plot_from_txt(results_file):
    distances = []
    with open(results_file, 'r') as f:
        for line in f:
            line_str, _, _, dist_str = line.split(' ')
            distances.append(float(dist_str))
    
    steps = list(range(int(line_str) + 1))
    plt.plot(steps, distances)
    plt.show()

# IMPORTANT: the number of lines of --sentences_file must be exactly equal to --len_sen
def parse_arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument('--results_file', action = 'store', nargs = '?', default = 'results.txt', type = str,
                        help = '储存分组结果的文本文件名，默认是由cluster.py执行自动生成的results.txt. txt file name to store clustering results; default to results.txt auto-generated by cluster.py')
    parser.add_argument('--second', action = 'store_true',
                        help = '表示第二次执行，跳过画图步骤，把到--step为止的分类结果储存在clusters.txt中，并在屏幕上打印. indicate it is the second time of run, so the plotting step will be skippped and store the clusters in clusters.txt at step given by --step')
    parser.add_argument('--sentences_file', action = 'store', nargs = '?', default = 'sentences.txt', type = str,
                        help = '储存句子文件的文本文件名，默认是由cluster.py执行自动生成的sentences.txt. txt file name to store all the sentences; default to sentences.txt auto-generated by cluster.py')
    parser.add_argument('--step', action = 'store', nargs = '?', default = 0, type = int,
                        help = '分类停止的步骤数. step at which the clustering should stop')
    parser.add_argument('--from_db', action = 'store_true',
                        help = '表示本地没有储存句子的文本文件，将从数据库直接读取，需要保证在cluster.py结\n束之后数据库没有任何变动并且同时提供\n如下的数据库信息. indicate that there is no local txt file to store all the sentences, so they will be loaded from the database; one has to ensure that the database has not been changed after execution of cluster.py')
    parser.add_argument('--host', action = 'store', nargs = '?', default = '127.0.0.1', type = str,
                        help = '数据库的IP地址，默认为localhost; the IP address of database. default to localhost')
    parser.add_argument('--port', action = 'store', nargs = '?', default = 3306, type = int,
                        help = '数据库端口号，默认为3306. the port of database; default to 3306')
    parser.add_argument('--user', action = 'store', nargs = '?', default = 'root', type = str,
                        help = '数据库的用户名，默认为root. the username of database; default to root')
    parser.add_argument('--passwd', action = 'store', nargs = '?', default = 'password', type = str,
                        help = '数据库用户名对应的密码，默认为password. passowrd for database; default to password')
    parser.add_argument('--db', action = 'store', nargs = '?', default = 'database', type = str,
                        help = '数据库的名称，默认为database. name of the database; default to database')
    parser.add_argument('--len_sen', action = 'store', nargs = '?', default = 1, type = int,
                        help = '所有进行分类的句子的总数，在给定--second的情况下必须提供，默认值为1. the total number of sentences to be clustered and must be presented when given --second; default to 1')
    parser.add_argument('--get_sen_sql', action = 'store', nargs = '?', 
                        default = u'SELECT sentence FROM table'.encode('utf-8'),
                        type = str,
                        help = '从数据库读出所有句子的SQL命令，默认为从table中读出句子，需要在句子前后加入\n英文状态下的引号. sql command to retrieve all sentences from a table; default to selecting all sentences from "table"')
    name_space = parser.parse_args()
    return name_space

def main():
    name_space = parse_arguments()
    if name_space.second:
        spend_time_wrapper(print_cl_from_txt, 'print clusters from txt file', name_space.results_file, name_space.step,
                           from_db = name_space.from_db, host = name_space.host, port = name_space.port, user = name_space.user, passwd = name_space.passwd, db = name_space.db,
                           len_sen = name_space.len_sen, get_sen_sql = name_space.get_sen_sql, sentences_file = name_space.sentences_file)
    else:
        spend_time_wrapper(plot_from_txt, 'plot distance graph from txt file', name_space.results_file)
    
if __name__ == '__main__':
    main()
        
